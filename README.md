# aics-project title: A Multimodal Siamese Network for Learning Similarity in the WikiDiverse Dataset
## An overview
Siamese networks consist of two identical sub-networks that share weights and learn to compute similarity between input pairs. This architecture is particularly effective for tasks requiring similarity learning, metric learning, or one-shot learning. 
For the **WikiDiverse dataset** - a multimodal collection of image-caption pairs - our implementation leverages Siamese networks to learn semantic similarity across different modalities (text and visual content).
## * Siamese Network Structure: Two identical sub-networks that compute embeddings for input pairs and learn their similarity
## * Application: For WikiDiverse, compute similarity between image-caption pairs to link knowledge-base entities.

## Contents of this Repository
-[Scripts](#Scripts) 
 Python scripts for training, evaluation, and analysis.
-[Notes](#Notes) 
 Figure, training results(metrics and verification), and other.
-[Paper](#Paper)
 The full paper detailing methodology, results, and discussions.
## Since the training dataset and models are large in size, I have uploaded them to the following Google Drive link:
-[Link](#Link) https://drive.google.com/drive/folders/1BCFgt429xTY2nM1ZHMTGFPJmfgvRVYyz

